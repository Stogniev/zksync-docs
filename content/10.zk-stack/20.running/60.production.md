---
title: In production
---

## Deploying to a non-local environment

The process to deploy to a non local environment is pretty similar to the local one.
The wizard allows you to set up URLs to external services (database, RPCs, etc).

When you are ready to deploy to a persistent environment (e.g., cloud VM or dedicated server),
begin with **one instance** of the server binary running all components (State Keeper, API, ETH Sender, etc.) in a monolithic setup.
This helps you gain familiarity with external hosting, system stability, and ongoing operations.

We encourage you to have one private experimental environment (devnet) throughout your journey.
Check the default configuration and understand what can be changed.
The config can be found under `chains/$NAME/configs` in your ecosystem directory, generated based on the [default configuration](https://github.com/matter-labs/zksync-era/tree/main/etc/env/file_based).

We recommend using a container orchestration system in production.
Having a container orchestration system simplifies scaling, updates and auto reprovisioning singletons after node failures.
We do not require use of Kubernetes specifically, you may achieve this objectives with a different solution (ex. Docker Swarm, Openshift).

::callout{icon="i-heroicons-light-bulb"}
We do not provide Helm charts.
::

## Database

The wizard allows you to provide a custom database url connector.
Make sure you provide it and that it accepts external connections if your server is not running in the same private network.

ZK Stack consists of 2 PG databases: main/server and prover.
They should be separated and independently scaled.

### Database Backup

For a production-level network, **replicating PostgreSQL is necessary** to avoid losing transaction data and chain state.

**Establish a backup strategy for your PostgreSQL database.**

Have fallback infrastructure for the server (eg. multiple Kubernetes nodes).
Recovering from a lost main PostgreSQL instance needs special tooling and can result in a long downtime.

Transaction list **cannot** be recovered from onchain or DA provider data.
*Only state can be recovered.*
Thus, performing a recovery from any PostgreSQL issue is very tricky, and we recommend to **take every possible precaution to avoid database data loss/corruption.**

## Server (Sequencer) & Prover

After configuring your ZK chain, you can generate docker images for your server and prover.
To do that run `zk stack docker-setup`.

This command will guide you to properly name and tag your image.
After building it, a docker compose file will be available so you can run the images on whichever cloud environment you desire.

::drop-panel

  ::panel{label="Server Components"}

| Component | Scaling | Responsibility | Dependencies | State Recovery | Load Pattern |
| --- | --- | --- | --- | --- | --- |
| `http_api` & `ws_api` (JSON-RPC API servers) | Autoscale  | ETH-like Web3 API | PSQL Master, PSQL Replicas | Stateless, in-memory cache | CPU + PSQL |
| `state_keeper` (sequencer) | Singleton | Packs transactions in blocks, mutates state | PSQL Master, own RocksDB | recovers from PSQL automatically (many hours) | CPU + PSQL |
| `tree` | *Manual scale* | * Maintains State Tree in RocksDB, Saves root hash in PSQL | PSQL Master, own RocksDB | recovers from PSQL automatically  (many days) | DISK + CPU + PSQL |
| `eth_watcher` & `eth_sender` | Singleton | * Fetches L1 state changes with ETH API (JSON-RPC), Performs L1 state changes (commit, prove, execute, base token ratio update)  | PSQL Master, Ethereum operator, blob operator, base token ratio setter, Wallets | Stateless | moderate load |
| `proof_data_handler` | Singleton | Sends proof-related info from Server to Prover and back | PSQL Master, GCS | Stateless | moderate load, network |
| `commitment_generator` | Singleton | Calculates commitment info for L1 batches | PSQL Master | Stateless | CPU |
| Snapshots creator | Singleton | Generates snapshots and stores them on GCS. Snapshots are useful to start EN. Uses separate docker image. | PSQL Master, It’s own PSQL replica, GCS | recovers from PSQL automatically | Very heavy PSQL IOPS load |
| `da_dispatcher` (for validiums only) | Singleton | Sends pubdata to the chosen DA provider | PSQL Master | Stateless | moderate load |
| `vm_runner_protective_reads` & `vm_runner_bwip` | Singleton (runs multiple VMs inside the process) | Prepares data for batch (merkle paths & basic witness inputs) | PSQL Master, GCS | Stateless, in-memory cache | CPU + PSQL |
| `housekeeper` | Singleton | (Currently) reports metrics. May perform some housekeeping tasks. | PSQL Master | Stateless | very low load |

  ::
::

## Monitoring

In production, make sure you are monitoring:

- **Infrastructure Health:** Components expose metrics that can be used to assess their health,including logs and CPU, memory, and disk usage.
- **RPC Health**: Response times, error rates.
- **Batch Production and Proving**: Use metrics to verify blocks are produced and proofs are generated.
- **Operator Wallet Balance**: Ensure your operator wallet doesn’t run out of ETH.
- **Active Chain Health Watchdog:** an optional recommended service that automatically performs small on-chain transactions to confirm liveness.

## Common procedures

Once your chain is live in production, there are some common procedures you will have to perform as a chain operator.
Before launching a chain, it's recommended to get familiar with each of these operations:

::drop-panel

  ::panel{label="Block reverts"}
  Both miniblock and batch reverts can be performed using [block-revert CLI tool](https://github.com/matter-labs/zksync-era/blob/c44f7a7317f170dfd7df97bb5f8709a6d810d9fc/core/bin/block_reverter/src/main.rs).
  Miniblock revert only changes the database state, where batch revert can be performed for not executed batches
  and, if they were sent to L1, involves calling L1 contracts.

  Both types of revert are a useful tool in recovering a chain that entered an invalid state.
  Block reverting preserves transactions that were included in discarded blocks by returning them to the pool.
  ::

  ::panel{label="Server upgrades"}
  [Server upgrades](https://github.com/matter-labs/zksync-era/releases)
  are done by first running database migration while the old version is running and then upgrading the server.
  To avoid incompatibility and thus downtime you should first upgrade to latest minor, before upgrading major.

  It’s highly discouraged to skip a major version (e.g. you should not upgrade from 24.9.0 to 26.2.0 without running 25.4.0 first).
  However please always consult release notes and account for any announcements made by the Matter Labs team.

  Server major version matches protocol version however each major also supports some previous protocol versions.
  Thus to upgrade protocol version you first upgrade the server version.
  ::

  ::panel{label="Protocol upgrades"}
  Protocol upgrades impact smart contracts.
  They are preceded by an [ecosystem vote](https://www.tally.xyz/gov/zksync) on mainnet and must be deployed by a certain deadline (~2-4 weeks).

  To execute an upgrade, a new protocol-compatible server must be deployed,
  and the upgrade time must be set using a
  [ChainAdmin](https://github.com/matter-labs/era-contracts/blob/3288adb0aee6c1c3022f6c817f95234764e0d611/l1-contracts/contracts/state-transition/chain-deps/facets/Admin.sol#L5)
  L1 operation.

  Provers must be handled carefully.
  Batches from the old protocol version must be fully processed before shutting down the old prover and starting the new one,
  as each prover binary supports only a single protocol version.
  Other components, such as the `state_keeper`, should never run multiple instances simultaneously.

  Each upgrade includes instructions as it may require some one-off procedure.
  Note that we support protocol upgrades only on shared bridge
  as there are upgrade operations performed on whole ecosystem that we do not provide instructions for.
  ::

  ::panel{label="Scaling"}
  You should be prepared to [scale provers](/zk-stack/running/proving#scaling-your-prover) if the chain load requires it.
  It is fine to do this manually.

  As too slow proving does not prevent block production, only withdrawals are affected
  (users may complete only withdrawals from proved blocks).
  For the RPC and [Block Explorer](/zk-stack/components/block-explorer#scaling-the-block-explorer), it is recommended to auto-scale the API under load.
  ::

::

## Security

Security in production is critical to the safety of your chain.
While this section does not exhaustively cover security for running a chain,
here are some important security requirements to consider:

- The chain admin (`ChainAdmin`) should be owned by a multisig.
  Make sure you have a secure process of managing critical keys
  We require this multisig has at least 4 owners and requires signature from at least 2 owners.
  If you have more owners the signatures to owners ratio should be reasonable.
- You must have a secret management solution in place.
  Avoid storing private keys for fee account or governor anywhere in the cluster.
  They are not required for the infra to work.
- Ensure limited access to infrastructure, including especially `eth-sender` secrets and main database.
